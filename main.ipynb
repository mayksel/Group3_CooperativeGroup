{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Group 3\n",
        "Authors:\n",
        "\n",
        "Barrion, Ryan Onil\n",
        "\n",
        "Geronimo, Michael Robert\n",
        "\n",
        "Roledo, Jan Carlo\n",
        "\n",
        "Solis, Frances Danielle"
      ],
      "metadata": {
        "id": "xw2YPJrHJO9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# C++ Version of Dot Product"
      ],
      "metadata": {
        "id": "AzxL1452tuan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile c_dotp.c\n",
        "#include <bits/stdc++.h>\n",
        "#include <ctime>\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "//C++ Dot Product Function\n",
        "void dot_product (int n, double *h_out, float* h_in1, float* h_in2){\n",
        "  for (int i = 0; i < n; i++)\n",
        "   *h_out += h_in1[i] * h_in2[i];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const unsigned int ARRAY_SIZE = 1<<24;\n",
        "    const unsigned ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "    const unsigned int run = 30;\n",
        "\n",
        "    float *in1, *in2;\n",
        "    double out = 0;\n",
        "    in1 = (float*)malloc(ARRAY_BYTES);\n",
        "    in2 = (float*)malloc(ARRAY_BYTES);\n",
        "\n",
        "    clock_t start, end;\n",
        "\n",
        "    //init data\n",
        "    for(int i = 0; i <ARRAY_SIZE;i++){\n",
        "        in1[i]=float(i);\n",
        "        in2[i]=float(i);\n",
        "    }\n",
        "    \n",
        "    dot_product(ARRAY_SIZE, &out, in1, in2);\n",
        "\n",
        "\n",
        "    double time_taken;\n",
        "    for(int i = 0; i<run; i++)\n",
        "      out = 0;\n",
        "      start = clock();\n",
        "      dot_product(ARRAY_SIZE, &out, in1, in2);\n",
        "      end = clock();\n",
        "      time_taken += (double)end-start;\n",
        "    \n",
        "    time_taken = ((time_taken)*1e6/CLOCKS_PER_SEC)/run;\n",
        "    printf(\"C++ function took an average of %lf microseconds for array size %d.\\n\", time_taken, ARRAY_SIZE);\n",
        "  \n",
        "    //Check for errors\n",
        "    double sum = 0;\n",
        "    for(int i = 0; i < ARRAY_SIZE; i++){\n",
        "      sum += in1[i] * in2[i];\n",
        "    }\n",
        "\n",
        "    cout << \"Output: \" << out << endl;\n",
        "    cout << \"Expected: \" << sum << endl;\n",
        "\n",
        "    double p_error = abs((out - sum) / sum) * 100.0;\n",
        "\n",
        "    cout << \"Percent Error: \" << p_error << endl;\n",
        "   \n",
        "   //free memory\n",
        "   free(in1);\n",
        "   free(in2);\n",
        "\n",
        "   return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ludT6zCltyGb",
        "outputId": "86514692-7456-4547-be6b-c272e99daba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing c_dotp.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "g++ c_dotp.c -o c_dotp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKNDzn9pt1Ps",
        "outputId": "ae4737d5-d5f9-4cf8-9807-89ef92e03e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./c_dotp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j9VplQ_t23O",
        "outputId": "6d2f71ff-cfee-4f4b-9e99-b58bd0b30298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C++ function took an average of 1766.433333 microseconds for array size 16777216.\n",
            "Output: 1.57412e+21\n",
            "Expected: 1.57412e+21\n",
            "Percent Error: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "#2. CUDA Without Cooperative Group Dot Product"
      ],
      "metadata": {
        "id": "9mxyL8vl65xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_uncooperative_threads.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__\n",
        "void dotProduct(float *x,float *y, double *dotp,long unsigned int ARRAY_SIZE){\n",
        "\n",
        "  extern __shared__ double mul_result[];\n",
        "  mul_result[threadIdx.x]  = 0.0;\n",
        "\n",
        "\n",
        "  int index = blockIdx.x * gridDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "\n",
        "  for (int i = blockIdx.x * gridDim.x + threadIdx.x; \n",
        "        i < ARRAY_SIZE;\n",
        "        i += blockDim.x * gridDim.x){\n",
        "      mul_result[threadIdx.x] += (double)y[i] * x[i];\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  if(threadIdx.x == 0){\n",
        "    double sum = 0.0;\n",
        "\n",
        "    for(int i = 0 ; i < blockDim.x; ++i){\n",
        "      sum = sum + mul_result[i];\n",
        "    }\n",
        "    atomicAdd(dotp, sum);\n",
        "  }\n",
        "\n",
        "}\n",
        "int main(void){\n",
        "\n",
        "  //number of runs\n",
        "  int runs = 30;\n",
        "\n",
        "  // Declare Number of Elements\n",
        "  const unsigned long int ARRAY_SIZE = 1<<24;\n",
        "  const unsigned long int ARRAY_BYTES = ARRAY_SIZE * sizeof(ARRAY_SIZE); \n",
        "\n",
        "  // Declare Dimensions\n",
        "  const int nBlocks = 1024;\n",
        "  const int nThreads = nBlocks;\n",
        "\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "\n",
        "  float *x, *y;\n",
        "  double *dotp;\n",
        "\n",
        "  // Allocate resources for variables x and y;\n",
        "  cudaMallocManaged(&x,ARRAY_BYTES);\n",
        "  cudaMallocManaged(&y, ARRAY_BYTES);\n",
        "\n",
        "  // Allocate only a single space to store the result of sum\n",
        "  cudaMallocManaged(&dotp, sizeof(double));\n",
        "  *dotp = 0.0;\n",
        "  \n",
        "  //Prefetch Part 1\n",
        "  cudaMemAdvise(x,ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(y,ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "\n",
        "  cudaMemPrefetchAsync(dotp,sizeof(double), device, NULL);\n",
        "\n",
        "  // Initialize Variables\n",
        "  for (int i = 0; i < ARRAY_SIZE; ++i){\n",
        "    x[i] = (float)((i + 1) % 50);\n",
        "    y[i]  = x[i] + 2.0;\n",
        "  }\n",
        "\n",
        "\n",
        "  // Prefetch Part 2\n",
        "  cudaMemAdvise(x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "  cudaMemAdvise(y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "\n",
        "  cudaMemAdvise(x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  cudaMemPrefetchAsync(x,ARRAY_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(y,ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // Initial launch to prevent additional time for cache miss\n",
        "\n",
        "  //Launch Kernel\n",
        "  for (int i=0; i<runs; i++){\n",
        "    cudaMemPrefetchAsync(dotp, sizeof(double), cudaCpuDeviceId, NULL);\n",
        "    *dotp = 0;\n",
        "    cudaMemPrefetchAsync(dotp, sizeof(double), device, NULL);\n",
        "\n",
        "    dotProduct<<<nBlocks,nThreads, sizeof(double) * nThreads>>>(x,y,dotp,ARRAY_SIZE);\n",
        "    cudaDeviceSynchronize();\n",
        "  }\n",
        "  \n",
        "  // Prefetch Result\n",
        "  cudaMemPrefetchAsync(dotp, sizeof(double), cudaCpuDeviceId, NULL);\n",
        "\n",
        "  // Check for Error by measuring percent error\n",
        "  double expected = 0;\n",
        "\n",
        "  for(int i = 0; i < ARRAY_SIZE; ++i){\n",
        "    expected = expected + (double)(x[i] * y[i]);\n",
        "  }\n",
        "\n",
        "  float pError = abs((dotp[0]-expected)/expected) * 100;\n",
        "\n",
        "  printf(\"\\n\\nNumber of Elements: %lu\\n\",ARRAY_SIZE);\n",
        "  printf(\"Number of Blocks: %d\\n\",nBlocks);\n",
        "  printf(\"Number of Threads: %d\\n\",nThreads);\n",
        "\n",
        "  printf(\"\\n\\nExpected:%f\\nComputed:%f\\n\\n\", dotp[0], expected );\n",
        "  printf(\"Percent Error: %f\\n\\n\",pError );\n",
        "\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "  cudaFree(dotp);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "NGwcHN8Z7HUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d2d636-62ac-4e6d-bfbd-6156f4632f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_uncooperative_threads.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvcc cuda_uncooperative_threads.cu -o cuda_uncooperative_threads -arch=sm_60 \n",
        "\n",
        "nvprof ./cuda_uncooperative_threads\n"
      ],
      "metadata": {
        "id": "6CVhAjGp7KB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da829341-53d0-4251-f28c-b7d8acf8d51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mcuda_uncooperative_threads.cu(12)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"index\"\u001b[0m was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcuda_uncooperative_threads.cu(13)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"stride\"\u001b[0m was declared but never referenced\n",
            "\n",
            "==15994== NVPROF is profiling process 15994, command: ./cuda_uncooperative_threads\n",
            "\n",
            "\n",
            "Number of Elements: 16777216\n",
            "Number of Blocks: 1024\n",
            "Number of Threads: 1024\n",
            "\n",
            "\n",
            "Expected:14386450768.000000\n",
            "Computed:14386450768.000000\n",
            "\n",
            "Percent Error: 0.000000\n",
            "\n",
            "==15994== Profiling application: ./cuda_uncooperative_threads\n",
            "==15994== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  104.84ms        30  3.4946ms  3.4928ms  3.4960ms  dotProduct(float*, float*, double*, unsigned long)\n",
            "      API calls:   73.36%  376.92ms         3  125.64ms  22.604us  376.84ms  cudaMallocManaged\n",
            "                   21.02%  108.01ms        30  3.6002ms  3.4966ms  6.4880ms  cudaDeviceSynchronize\n",
            "                    2.62%  13.482ms         3  4.4939ms  2.7956ms  5.5441ms  cudaFree\n",
            "                    1.53%  7.8846ms         6  1.3141ms  1.8320us  4.3542ms  cudaMemAdvise\n",
            "                    1.20%  6.1475ms        64  96.055us  9.9680us  4.6144ms  cudaMemPrefetchAsync\n",
            "                    0.15%  787.81us         1  787.81us  787.81us  787.81us  cuDeviceGetPCIBusId\n",
            "                    0.08%  405.37us        30  13.512us  7.3350us  75.965us  cudaLaunchKernel\n",
            "                    0.03%  132.56us       101  1.3120us     143ns  54.517us  cuDeviceGetAttribute\n",
            "                    0.01%  25.724us         1  25.724us  25.724us  25.724us  cuDeviceGetName\n",
            "                    0.00%  3.6860us         1  3.6860us  3.6860us  3.6860us  cudaGetDevice\n",
            "                    0.00%  1.8990us         3     633ns     241ns  1.4100us  cuDeviceGetCount\n",
            "                    0.00%  1.2910us         2     645ns     182ns  1.1090us  cuDeviceGet\n",
            "                    0.00%     636ns         1     636ns     636ns     636ns  cuModuleGetLoadingMode\n",
            "                    0.00%     444ns         1     444ns     444ns     444ns  cuDeviceTotalMem\n",
            "                    0.00%     256ns         1     256ns     256ns     256ns  cuDeviceGetUuid\n",
            "\n",
            "==15994== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      95  1.3486MB  4.0000KB  2.0000MB  128.1211MB  11.45574ms  Host To Device\n",
            "      31  4.0000KB  4.0000KB  4.0000KB  124.0000KB  63.83900us  Device To Host\n",
            "Total CPU Page faults: 66\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "#3. CUDA Cooperative Group Dot Product\n",
        "##3.1 Replacing __syncthreads with thread_block.sync()"
      ],
      "metadata": {
        "id": "Tf3h-SpKOw71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_group.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <cooperative_groups.h>\n",
        "\n",
        "using namespace cooperative_groups;\n",
        "namespace cg = cooperative_groups;\n",
        "\n",
        "#define BLOCK_SIZE 1024\n",
        "\n",
        "//device \"sub-function\" to generate a partial sum of the dot products of 4 consecutive elements\n",
        "__device__ double thread_dot(float *input1, float *input2, int n) \n",
        "{\n",
        "    double sum = 0;\n",
        "\n",
        "    //grid-stride loop \n",
        "    for(int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "        i < n / 4; //only 1/4 because float4 takes 4 elements\n",
        "        i += blockDim.x * gridDim.x)\n",
        "    {\n",
        "        //fetch 4 inputs at once, into a 4-element vector\n",
        "        float4 in1 = ((float4*)input1)[i];\n",
        "        float4 in2 = ((float4*)input2)[i];\n",
        "\n",
        "        //perform partial dot product of 4 elements at a time\n",
        "        sum += (in1.x*in2.x) + (in1.y*in2.y) + (in1.z*in2.z) + (in1.w*in2.w);\n",
        "    }\n",
        "    return sum;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "//device \"sub-function\" to fill shared memory and add elements in parallel\n",
        "__device__\n",
        "double reduction_dotprod(thread_block g, double *temp, double val){\n",
        "\n",
        "  //get thread index\n",
        "  int lane = g.thread_rank();\n",
        "\n",
        "  //binary reduction loop\n",
        "  for (int i = g.size() / 2; i > 0; i /= 2){        \n",
        "    temp[lane] = val;\n",
        "    g.sync(); //wait for threads to store\n",
        "    if (lane < i) val += temp[lane + i];\n",
        "    g.sync(); //wait for threads to load\n",
        "  }\n",
        "\n",
        "  return val;\n",
        "}\n",
        "\n",
        "\n",
        "//main kernel function\n",
        "//initializes thread blocks and combines results of \n",
        "__global__\n",
        "void dotprod_group(int n, float *in_x, float *in_y, double *out){\n",
        "\n",
        "  double init_sum = thread_dot(in_x, in_y, n);\n",
        "\n",
        "  //create shared memory space\n",
        "  extern __shared__ double temp[];\n",
        "\n",
        "  //initialize thread block for binary-reduction sum\n",
        "  auto g = this_thread_block();\n",
        "\n",
        "  //perform reduction sum\n",
        "  double block_sum = reduction_dotprod(g, temp, init_sum);\n",
        "\n",
        "  //the first thread (thread 0) will have the final result\n",
        "  if (threadIdx.x == 0){\n",
        "    atomicAdd(out, block_sum);\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\n",
        "  //number of runs\n",
        "  int runs = 30;\n",
        "\n",
        "  const unsigned int ARRAY_SIZE = 1<<24;\n",
        "\n",
        "  const unsigned int ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
        "\n",
        "  //size of shared bytes in sum_group() kernel\n",
        "  const unsigned int SHARED_BYTES = BLOCK_SIZE * sizeof(double);\n",
        "\n",
        "  const int NUM_BLOCKS = BLOCK_SIZE;\n",
        "  printf(\"numElem = %d\\tnumThreads = %d\\tnumBlocks = %d\\n\", ARRAY_SIZE, BLOCK_SIZE, NUM_BLOCKS);\n",
        "\n",
        "  //declare ARRAY_BYTES or allocate in GPU\n",
        "  float *in_x, *in_y;\n",
        "  double *out;\n",
        "  cudaMallocManaged(&in_x, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&in_y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, sizeof(double));\n",
        "\n",
        "  //prefetch input data to CPU\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  //init data\n",
        "  for(int i = 0; i < ARRAY_SIZE; i++)\n",
        "    in_x[i] = in_y[i] = 0.000001f * i;\n",
        "\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device); // get device number of GPU\n",
        "\n",
        "  cudaMemPrefetchAsync(out, sizeof(double), device, NULL);\n",
        "\n",
        "  //Prefetch and Memory Advise input data to device\n",
        "  cudaMemAdvise(in_x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  cudaMemAdvise(in_y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  for(int i=0; i<runs;i++){\n",
        "    cudaMemPrefetchAsync(out, sizeof(double), cudaCpuDeviceId, NULL);\n",
        "    *out = 0;\n",
        "    cudaMemPrefetchAsync(out, sizeof(double), device, NULL);\n",
        "\n",
        "    //perform dot product with Cooperative Groups (thread_block)\n",
        "    dotprod_group<<<NUM_BLOCKS, BLOCK_SIZE, SHARED_BYTES>>> (ARRAY_SIZE, in_x, in_y, out); \n",
        "    \n",
        "    cudaDeviceSynchronize();\n",
        "  }\n",
        "\n",
        "\n",
        "  //prefetch input data to CPU\n",
        "  cudaMemAdvise(in_x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  cudaMemAdvise(in_y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  cudaMemAdvise(out, sizeof(double), cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(out, sizeof(double), cudaCpuDeviceId, NULL);\n",
        "\n",
        "  //check for errors\n",
        "  double sum = 0;\n",
        "  for(int i = 0; i < ARRAY_SIZE/2; i++) {\n",
        "    sum += (in_x[i] * in_y[i] + in_x[i+ARRAY_SIZE/2] * in_y[i+ARRAY_SIZE/2]);\n",
        "  }\n",
        "\n",
        "  double sum_seq = 0;\n",
        "  for (int i = 0; i < ARRAY_SIZE; i++){\n",
        "    sum_seq += in_x[i] * in_y[i];\n",
        "  }\n",
        "  printf(\"Sequential Sum: %lf\\t\", sum_seq);\n",
        "  printf(\"'Binary Split' Sum: %lf\\t Coop-Group Reduction Sum: %lf\\n\",sum, *out);\n",
        "\n",
        "  double diff = abs((*out - sum) / sum) * 100.0;\n",
        "\n",
        "  printf(\"Difference with split sum: %.5f%%\\n\", diff);\n",
        "\n",
        "  //free memory in GPU\n",
        "  cudaFree(in_x);\n",
        "  cudaFree(in_y);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d388a56-c8dd-4b83-bcfe-87e1d28164cb",
        "id": "94MPcY77v2uL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_group.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_group.cu -o cuda_group -arch=sm_60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce1cbb3-45ac-4b9a-b396-b9d37594ca77",
        "id": "gG_mzcEgv2uQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_group"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b921d46-cb23-48dd-f900-cafd9de0108c",
        "id": "oxwnn-rAv2uQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numElem = 16777216\tnumThreads = 1024\tnumBlocks = 1024\n",
            "==20207== NVPROF is profiling process 20207, command: ./cuda_group\n",
            "Sequential Sum: 1574122012.273521\t'Binary Split' Sum: 1574122012.255829\t Coop-Group Reduction Sum: 1574122010.090982\n",
            "Difference with split sum: 0.00000%\n",
            "==20207== Profiling application: ./cuda_group\n",
            "==20207== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  19.639ms        30  654.63us  646.48us  661.84us  dotprod_group(int, float*, float*, double*)\n",
            "      API calls:   76.13%  266.51ms         3  88.837ms  19.577us  266.44ms  cudaMallocManaged\n",
            "                   12.18%  42.622ms        68  626.80us  13.267us  17.268ms  cudaMemPrefetchAsync\n",
            "                    5.68%  19.877ms        30  662.58us  654.72us  722.33us  cudaDeviceSynchronize\n",
            "                    3.92%  13.710ms         3  4.5701ms  126.81us  7.6223ms  cudaFree\n",
            "                    1.95%  6.8399ms         5  1.3680ms  2.4850us  3.4856ms  cudaMemAdvise\n",
            "                    0.10%  355.07us        30  11.835us  6.7760us  55.468us  cudaLaunchKernel\n",
            "                    0.03%  121.31us       101  1.2010us     127ns  51.571us  cuDeviceGetAttribute\n",
            "                    0.01%  26.388us         1  26.388us  26.388us  26.388us  cuDeviceGetName\n",
            "                    0.00%  6.9450us         1  6.9450us  6.9450us  6.9450us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.8270us         1  4.8270us  4.8270us  4.8270us  cudaGetDevice\n",
            "                    0.00%  1.9770us         3     659ns     204ns  1.4700us  cuDeviceGetCount\n",
            "                    0.00%  1.0690us         2     534ns     285ns     784ns  cuDeviceGet\n",
            "                    0.00%     421ns         1     421ns     421ns     421ns  cuDeviceTotalMem\n",
            "                    0.00%     367ns         1     367ns     367ns     367ns  cuModuleGetLoadingMode\n",
            "                    0.00%     207ns         1     207ns     207ns     207ns  cuDeviceGetUuid\n",
            "\n",
            "==20207== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      94  1.3630MB  4.0000KB  2.0000MB  128.1172MB  11.28263ms  Host To Device\n",
            "      31  4.0000KB  4.0000KB  4.0000KB  124.0000KB  66.14500us  Device To Host\n",
            "Total CPU Page faults: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3.2 Subgrouping\n",
        "\n",
        "By creating static sized subgroups out of the current thread blocks, we can perform some compiler optimization tricks to improve performance.\n",
        "\n",
        "Here, we make 32-thread subgroups from the original thread group, and unroll the loop within the reduction sum device function."
      ],
      "metadata": {
        "id": "itbbLctYpcw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_group_32.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <cooperative_groups.h>\n",
        "\n",
        "using namespace cooperative_groups;\n",
        "namespace cg = cooperative_groups;\n",
        "\n",
        "#define BLOCK_SIZE 1024\n",
        "\n",
        "\n",
        "//device \"sub-function\" to generate a partial sum of the dot products of 4 consecutive elements\n",
        "__device__ double thread_dot(float *input1, float *input2, int n) \n",
        "{\n",
        "    double sum = 0;\n",
        "\n",
        "    //grid-stride loop \n",
        "    for(int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "        i < n / 4; //only 1/4 because float4 takes 4 elements\n",
        "        i += blockDim.x * gridDim.x)\n",
        "    {\n",
        "        //fetch 4 inputs at once, into a 4-element vector\n",
        "        float4 in1 = ((float4*)input1)[i];\n",
        "        float4 in2 = ((float4*)input2)[i];\n",
        "\n",
        "        //perform partial dot product of 4 elements at a time\n",
        "        sum += (in1.x*in2.x) + (in1.y*in2.y) + (in1.z*in2.z) + (in1.w*in2.w);\n",
        "    }\n",
        "    return sum;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "//device \"sub-function\" to fill shared memory and add partial sums in parallel\n",
        "template <typename group_t>\n",
        "__device__\n",
        "double reduction_dotprod(group_t g, double *temp, double val){\n",
        "\n",
        "  //get thread index\n",
        "  int lane = g.thread_rank();\n",
        "\n",
        "  //binary reduction loop\n",
        "  //unroll is possible since group size is static and known at compile-time\n",
        "  #pragma unroll\n",
        "  for (int i = g.size() / 2; i > 0; i /= 2){        \n",
        "    temp[lane] = val;\n",
        "    g.sync(); //wait for threads to store\n",
        "    if (lane < i) val += temp[lane + i];\n",
        "    g.sync(); //wait for threads to load\n",
        "  }\n",
        "\n",
        "  return val;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void dotprod_group_32(int n, float *in_x, float *in_y, double *out){\n",
        "\n",
        "  //get partial sum `init_sum`\n",
        "  double init_sum = thread_dot(in_x, in_y, n);\n",
        "\n",
        "  //create shared memory space\n",
        "  extern __shared__ double temp[];\n",
        "\n",
        "  //initialize thread block for binary-reduction sum\n",
        "  auto g = this_thread_block();\n",
        "\n",
        "  //create 32-thread tiles and get pointer to matching temp value\n",
        "  int tileIdx = g.thread_rank() / 32;\n",
        "  double *t = &temp[32*tileIdx];\n",
        "\n",
        "  //create a static sized group\n",
        "  thread_block_tile<32> tile32 = tiled_partition<32>(this_thread_block());\n",
        "\n",
        "  //perform reduction sum\n",
        "  double tile_sum = reduction_dotprod<thread_block_tile<32>>(tile32, t, init_sum);\n",
        "\n",
        "  //the first thread (thread 0) will have the final result\n",
        "  if (tile32.thread_rank() == 0){\n",
        "    atomicAdd(out, tile_sum);\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "\n",
        "  int runs = 30;\n",
        "\n",
        "  const unsigned int ARRAY_SIZE = 1<<24;\n",
        "\n",
        "  const unsigned int ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
        "\n",
        "  //size of shared bytes in sum_group() kernel\n",
        "  const unsigned int SHARED_BYTES = BLOCK_SIZE * sizeof(double);\n",
        "\n",
        "  //matching block size and number of blocks greatly improves performance\n",
        "  const int NUM_BLOCKS = BLOCK_SIZE;\n",
        "  printf(\"numElem = %d\\tnumThreads = %d\\tnumBlocks = %d\\n\", ARRAY_SIZE, BLOCK_SIZE, NUM_BLOCKS);\n",
        "\n",
        "  //declare ARRAY_BYTES or allocate in GPU\n",
        "  float *in_x, *in_y;\n",
        "  double *out;\n",
        "  cudaMallocManaged(&in_x, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&in_y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, sizeof(double));\n",
        "\n",
        "  //prefetch input data to CPU\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  //init data\n",
        "  for(int i = 0; i < ARRAY_SIZE; i++)\n",
        "    in_x[i] = in_y[i] = 0.000001f * i;\n",
        "\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device); // get device number of GPU\n",
        "\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  //Prefetch and Memory Advise input data to device\n",
        "  cudaMemAdvise(in_x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  cudaMemAdvise(in_y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  cudaMemPrefetchAsync(out, sizeof(double), device, NULL);\n",
        "\n",
        "\n",
        "  //perform dot product with Cooperative Groups (thread_block)\n",
        "  for(int i=0; i<runs; i++){\n",
        "    cudaMemPrefetchAsync(out, sizeof(double), cudaCpuDeviceId, NULL);\n",
        "    *out= 0;\n",
        "    cudaMemPrefetchAsync(out, sizeof(double), device, NULL);\n",
        "\n",
        "    dotprod_group_32<<<NUM_BLOCKS, BLOCK_SIZE, SHARED_BYTES>>> (ARRAY_SIZE, in_x, in_y, out);\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "  }\n",
        "\n",
        "\n",
        "  //prefetch input data to CPU\n",
        "  cudaMemAdvise(in_x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  cudaMemAdvise(in_y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  cudaMemAdvise(out, sizeof(float), cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(out, sizeof(float), cudaCpuDeviceId, NULL);\n",
        "\n",
        "  //check for errors\n",
        "  double sum = 0;\n",
        "  for(int i = 0; i < ARRAY_SIZE/2; i++) {\n",
        "    sum += (in_x[i] * in_y[i] + in_x[i+ARRAY_SIZE/2] * in_y[i+ARRAY_SIZE/2]);\n",
        "  }\n",
        "\n",
        "  double sum_seq = 0;\n",
        "  for (int i = 0; i < ARRAY_SIZE; i++){\n",
        "    sum_seq += in_x[i] * in_y[i];\n",
        "  }\n",
        "  printf(\"Sequential Sum: %lf\\t\", sum_seq);\n",
        "  printf(\"'Binary Split' Sum: %lf\\t Coop-Group Reduction Sum: %lf\\n\",sum, *out);\n",
        "\n",
        "  double diff = abs((*out - sum) / sum) * 100.0;\n",
        "\n",
        "  printf(\"Difference with split sum: %.5f%%\\n\", diff);\n",
        "\n",
        "  //free memory in GPU\n",
        "  cudaFree(in_x);\n",
        "  cudaFree(in_y);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pAuFwh1VtJb",
        "outputId": "d9c3dae5-b9dc-4649-8220-34128e287801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_group_32.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_group_32.cu -o cuda_group_32 -arch=sm_60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c11dce-2221-4481-d758-f87b1fefcd89",
        "id": "JJkuSb6-dmHi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_group_32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089e4853-f9f5-43c1-b598-847d11a6a044",
        "id": "HwnapwnDdmHi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numElem = 16777216\tnumThreads = 1024\tnumBlocks = 1024\n",
            "==21150== NVPROF is profiling process 21150, command: ./cuda_group_32\n",
            "Sequential Sum: 1574122012.273521\t'Binary Split' Sum: 1574122012.255829\t Coop-Group Reduction Sum: 1574122010.090982\n",
            "Difference with split sum: 0.00000%\n",
            "==21150== Profiling application: ./cuda_group_32\n",
            "==21150== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  15.168ms        30  505.59us  504.15us  506.90us  dotprod_group_32(int, float*, float*, double*)\n",
            "      API calls:   77.12%  273.58ms         3  91.192ms  18.264us  273.52ms  cudaMallocManaged\n",
            "                   13.22%  46.898ms        69  679.68us  7.0680us  18.578ms  cudaMemPrefetchAsync\n",
            "                    5.10%  18.081ms        30  602.72us  507.70us  3.2729ms  cudaDeviceSynchronize\n",
            "                    2.58%  9.1600ms         3  3.0533ms  109.70us  4.6055ms  cudaFree\n",
            "                    1.84%  6.5100ms         5  1.3020ms  1.4350us  3.2880ms  cudaMemAdvise\n",
            "                    0.09%  322.26us        30  10.742us  6.3970us  44.163us  cudaLaunchKernel\n",
            "                    0.04%  145.15us       101  1.4370us     136ns  58.690us  cuDeviceGetAttribute\n",
            "                    0.01%  26.193us         1  26.193us  26.193us  26.193us  cuDeviceGetName\n",
            "                    0.00%  6.4920us         1  6.4920us  6.4920us  6.4920us  cuDeviceGetPCIBusId\n",
            "                    0.00%  5.3080us         1  5.3080us  5.3080us  5.3080us  cudaGetDevice\n",
            "                    0.00%  1.5440us         3     514ns     198ns  1.0250us  cuDeviceGetCount\n",
            "                    0.00%  1.0030us         2     501ns     280ns     723ns  cuDeviceGet\n",
            "                    0.00%     485ns         1     485ns     485ns     485ns  cuDeviceTotalMem\n",
            "                    0.00%     385ns         1     385ns     385ns     385ns  cuModuleGetLoadingMode\n",
            "                    0.00%     220ns         1     220ns     220ns     220ns  cuDeviceGetUuid\n",
            "\n",
            "==21150== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      95  1.3486MB  4.0000KB  2.0000MB  128.1211MB  11.35606ms  Host To Device\n",
            "      31  4.0000KB  4.0000KB  4.0000KB  124.0000KB  64.09600us  Device To Host\n",
            "Total CPU Page faults: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cooperative Group Reference: https://developer.nvidia.com/blog/cooperative-groups/\n",
        "\n",
        "Equal Thread count and Block count results in faster performance (correlational): http://selkie.macalester.edu/csinparallel/modules/CUDAArchitecture/build/html/2-Findings/Findings.html\n",
        "\n"
      ],
      "metadata": {
        "id": "LiXNSH2UL-4k"
      }
    }
  ]
}